{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實作 1 - 二元分類問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 導入所需的套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 導入Python的數據處理套件\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "## 導入視覺化套件\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## 導入Sklearn中的線性模組\n",
    "from sklearn import linear_model\n",
    "\n",
    "## 將數據集分成訓練集與測試集的套件\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 導入數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jack</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allen</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jen</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dora</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Doris</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cindy</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ken</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Angel</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tom</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tonny</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cathy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Candy</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>James</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jennica</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Alex</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Jessica</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Candy</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Student  Hours  Pass\n",
       "0      Jack      4     1\n",
       "1     Allen      4     1\n",
       "2       Jen      2     0\n",
       "3      Dora      3     0\n",
       "4      John      1     0\n",
       "5     Doris      1     0\n",
       "6     Cindy      3     1\n",
       "7       Ken      3     1\n",
       "8     Angel      4     0\n",
       "9       Tom      4     1\n",
       "10    Tonny      1     0\n",
       "11    Cathy      1     1\n",
       "12    Candy      2     1\n",
       "13    James      2     0\n",
       "14  Jennica      3     1\n",
       "15    Jenny      3     1\n",
       "16     Alex      3     0\n",
       "17  Jessica      3     0\n",
       "18    Candy      2     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 導入數據集\n",
    "data = pd.read_csv('dataset/logistic_regression_sample.csv')\n",
    "\n",
    "## 顯示數據集\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 定義自變量與應變量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent Variable:  [4 4 2 3 1 1 3 3 4 4 1 1 2 2 3 3 3 3 2]\n",
      "Dependent Variable:  [1 1 0 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "## 定義自變量與應變量\n",
    "X = data['Hours'].values\n",
    "y = data['Pass'].values\n",
    "\n",
    "print('Independent Variable: ', X)\n",
    "print('Dependent Variable: ', y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: 將特徵向量轉為2D向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape:  (19,)\n",
      "[[4]\n",
      " [4]\n",
      " [2]\n",
      " [3]\n",
      " [1]\n",
      " [1]\n",
      " [3]\n",
      " [3]\n",
      " [4]\n",
      " [4]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [2]]\n",
      "After reshaping data to 2D vector :  (19, 1)\n"
     ]
    }
   ],
   "source": [
    "## 由於 Sklearn 能接受的特徵格式為 (n_samples, n_features)，所以使用 reshape 將特徵資料轉為2D向量，這樣 Sklearn 才能使用，一般狀況下，一維特徵才需要轉換\n",
    "print('Original X shape: ', X.shape)\n",
    "\n",
    "## reshape用法: -1代表自動配置幾個框框(程式會自行根據有幾個值配置幾個框框架，也就是拿總共的數量除以後面設定框框內有幾個值)\n",
    "## 轉為2D向量\n",
    "X = X.reshape(-1, 1)\n",
    "print(X)\n",
    "print('After reshaping data to 2D vector : ', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: 將數據集分成訓練集與測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 將數據集分成訓練集與測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 建立邏輯迴歸模型 Logistic Regression Model 與訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 建立邏輯迴歸模型\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "## 擬和數據\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: 檢視模型係數與截距 Coeficient & Interception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficient:  0.5672535305693119\n",
      "Interception:  -1.3328997193245475\n"
     ]
    }
   ],
   "source": [
    "## 查看建出來的模型係數與截距 y = w1x + w0\n",
    "w1 = float(model.coef_)\n",
    "w0 = float(model.intercept_)\n",
    "\n",
    "print('Coeficient: ', w1)\n",
    "print('Interception: ', w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Sigmoid - 套入轉換函數 (將Logit(Odds)值轉換成 -> 0~1之間的數值)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 套用 Sigmoid轉換函數，將值轉換成介於0~1 之間的值(機率)\n",
    "def sigmoid(x, w0, w1):\n",
    "    logit_odds = w0 + w1 * x\n",
    "    return 1 / (1 + np.exp(-logit_odds))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: 視覺化轉換結果圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1a74aab35c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 視覺化後Sigmoid圖\n",
    "x = np.arange(0, 20, 1)\n",
    "result = sigmoid(x, w0, w1)\n",
    "\n",
    "plt.plot(x, result)\n",
    "\n",
    "## 畫出50%的機率線\n",
    "plt.axhline(y = 0.5, ls = 'dotted', color = 'y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: 預測測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Result:  [0 1 0 1]\n",
      "Model Predict:  [1 1 0 0]\n",
      "Define your own data and predict:  [0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "## 預測測試集\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print('Real Result: ', y_test)\n",
    "print('Model Predict: ', prediction)\n",
    "\n",
    "\n",
    "## 預測自行定義的數據集\n",
    "result = model.predict([[1], [2], [2.5], [3], [3.5], [4], [5], [6]])\n",
    "\n",
    "print('Define your own data and predict: ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: 模型預測測試集中每筆數據為0或1的機率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability (0 or 1) [[0.4088163  0.5911837 ]\n",
      " [0.4088163  0.5911837 ]\n",
      " [0.54943612 0.45056388]\n",
      " [0.54943612 0.45056388]]\n"
     ]
    }
   ],
   "source": [
    "## 預測測試集為1或0的機率\n",
    "proba = model.predict_proba(X_test)\n",
    "print('Probability (0 or 1)', proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: 模型表現 - 準確度 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :50.0%\n"
     ]
    }
   ],
   "source": [
    "## 模型表現\n",
    "score = model.score(X_test, y_test)\n",
    "print('Accuracy :' + str(score * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實作 2 - 多元分類問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: 導入所需的套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 導入Python的數據處理套件\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "## 導入視覺化套件\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## 導入Sklearn中的線性模組\n",
    "from sklearn import linear_model\n",
    "## 導入Sklearn的內建數據集\n",
    "from sklearn import datasets\n",
    "\n",
    "## 將數據集分成訓練集與測試集的套件\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: 導入數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 導入iris數據集(鳶尾花數據集)\n",
    "iris_data = datasets.load_iris()\n",
    "## 顯示數據集\n",
    "print(iris_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: 定義自變量與應變量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Independent Variable:  [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "Dependent Variable:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "## 定義自變量與應變量\n",
    "X = iris_data.data\n",
    "y = iris_data.target\n",
    "\n",
    "print('Independent Variable: ', X)\n",
    "print('Dependent Variable: ', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: 將數據集分成訓練集與測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 將數據集分成訓練集與測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 建立邏輯迴歸模型 Logistic Regression Model 與訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 建立邏輯迴歸模型\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "## 擬和數據\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: 預測測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real y (test data):  [0 1 2 1 1 2 2 1 2 1 1 2 0 2 0 2 0 2 2 2 1 1 0 2 1 2 2 1 1 2]\n",
      "Predict y (test data) [0 1 2 1 1 2 2 1 2 1 2 2 0 2 0 2 0 2 2 2 1 1 0 2 1 2 1 1 1 2]\n",
      "Probability (0 or 1 or 2):  [[9.63686532e-01 3.63132924e-02 1.75222019e-07]\n",
      " [1.07574506e-02 8.98088376e-01 9.11541730e-02]\n",
      " [2.49142162e-05 1.27485520e-01 8.72489566e-01]\n",
      " [2.35798020e-02 9.30301769e-01 4.61184292e-02]\n",
      " [2.19478761e-02 9.46475534e-01 3.15765897e-02]\n",
      " [1.43602535e-04 1.30353278e-01 8.69503120e-01]\n",
      " [1.11362279e-07 5.34629536e-03 9.94653593e-01]\n",
      " [1.03123468e-02 7.98148327e-01 1.91539326e-01]\n",
      " [5.56104282e-05 1.06288516e-01 8.93655874e-01]\n",
      " [3.15857582e-03 7.78516615e-01 2.18324809e-01]\n",
      " [7.69095917e-04 4.55551926e-01 5.43678978e-01]\n",
      " [2.36721813e-05 2.99622625e-02 9.70014065e-01]\n",
      " [9.80272061e-01 1.97278939e-02 4.48886032e-08]\n",
      " [7.31795353e-04 2.97582532e-01 7.01685672e-01]\n",
      " [9.73794169e-01 2.62057313e-02 9.97324567e-08]\n",
      " [1.44802727e-03 4.78512696e-01 5.20039277e-01]\n",
      " [9.79315374e-01 2.06845311e-02 9.47643193e-08]\n",
      " [2.04774841e-05 5.14453109e-02 9.48534212e-01]\n",
      " [7.54948158e-06 1.88378930e-02 9.81154558e-01]\n",
      " [8.96436493e-05 7.67452806e-02 9.23165076e-01]\n",
      " [1.09059868e-02 9.17394806e-01 7.16992073e-02]\n",
      " [1.88977619e-02 9.33269622e-01 4.78326163e-02]\n",
      " [9.49038620e-01 5.09607872e-02 5.92959951e-07]\n",
      " [4.38823090e-06 2.96993680e-02 9.70296244e-01]\n",
      " [5.85053775e-03 8.15952293e-01 1.78197169e-01]\n",
      " [4.09752857e-04 2.23191236e-01 7.76399012e-01]\n",
      " [7.61732149e-03 6.37508336e-01 3.54874343e-01]\n",
      " [2.50183895e-03 7.75078871e-01 2.22419290e-01]\n",
      " [1.34214049e-01 8.62185634e-01 3.60031710e-03]\n",
      " [1.09755114e-06 1.65768773e-02 9.83422025e-01]]\n"
     ]
    }
   ],
   "source": [
    "## 預測測試集\n",
    "prediction = model.predict(X_test)\n",
    "print('Real y (test data): ', y_test)\n",
    "print('Predict y (test data)', prediction)\n",
    "\n",
    "## 查看模型預測0、1、2的機率\n",
    "probability = model.predict_proba(X_test)\n",
    "print('Probability (0 or 1 or 2): ', probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: 模型表現 - 準確度 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Train Data): 99.16666666666667%\n",
      "Accuracy (Test Data): 93.33333333333333%\n"
     ]
    }
   ],
   "source": [
    "## 模型預測訓練集的準確度\n",
    "accuracy_train = model.score(X_train, y_train)\n",
    "print('Accuracy (Train Data): ' + str(accuracy_train * 100) + '%')\n",
    "\n",
    "## 模型預測測試集的準確度\n",
    "accuracy_test = model.score(X_test, y_test)\n",
    "print('Accuracy (Test Data): ' + str(accuracy_test * 100) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: 邏輯迴歸模型 Logistic Regression Model 的其他相關資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
